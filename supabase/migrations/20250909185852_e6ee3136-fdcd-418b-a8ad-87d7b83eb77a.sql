-- Insert default portfolio data
INSERT INTO public.portfolio_data (data) VALUES ('{
  "hero": {
    "name": "Ajith Annavarapu",
    "title": "Data Engineer & Data Scientist", 
    "subtitle": "Transforming raw data into meaningful insights",
    "description": "I transform raw data into meaningful insights that drive business decisions. With expertise in building robust data pipelines and scalable data systems, I help organizations harness the full potential of their data.",
    "openTo": "I am always open to new challenges and collaborations. If you are working on an interesting project that requires data expertise, A.I or even Vibe Coding. I would love to hear about it!"
  },
  "about": {
    "name": "Ajith Annavarapu",
    "bio": "I am a passionate Data Engineer with a Master degree in Data Science, dedicated to building robust and scalable data systems that transform raw data into valuable insights.",
    "location": "Irving, TX", 
    "education": "M.S. in Data Science",
    "email": "ajith.anna5599@gmail.com",
    "paragraph1": "I am a passionate Data Engineer with a Master degree in Data Science, dedicated to building robust and scalable data systems that transform raw data into valuable insights.",
    "paragraph2": "When I am not immersed in data, you will find me exploring new hiking trails, Vibe Coding, experimenting with cooking recipes, or diving into a good thriller movie. I believe in continuous learning and staying curious about the world around us.",
    "paragraph3": "I am always open to new challenges and collaborations. If you are working on an interesting project that requires data expertise, I would love to hear about it!"
  },
  "experience": [
    {
      "id": "1",
      "company": "Infokeys", 
      "role": "AI Data Engineer",
      "period": "Apr 2024â€“Present",
      "description": "Led migration of ETL workflows to Databricks, developed data governance frameworks, and implemented AI-driven monitoring systems.",
      "responsibilities": [
        "Led migration of ETL workflows to Databricks",
        "Developed data governance frameworks", 
        "Implemented AI-driven monitoring systems",
        "Created data optimization strategies in Snowflake",
        "Integrated LLMs for metadata tagging and automated reporting",
        "Significantly improving processing time, reducing costs, and enhancing data quality and accessibility"
      ],
      "technologies": ["Databricks", "Snowflake", "Python", "SQL", "LLMs", "ETL", "AI"]
    }
  ],
  "projects": [
    {
      "id": "1", 
      "title": "Data Cleaning Automation",
      "description": "Automated data cleaning and preprocessing pipeline for handling complex datasets efficiently.",
      "longDescription": "Automated data cleaning and preprocessing pipeline for handling complex datasets efficiently.",
      "techStack": ["Python", "Pandas", "Numpy", "Scikit-learn", "Jupyter Notebooks"],
      "githubLink": "https://github.com/Ajith-oo7/Cleaning-Automation",
      "color": "purple",
      "challenges": ["Handling complex data inconsistencies", "Automating manual cleaning processes", "Maintaining data quality"],
      "solutions": ["Built automated validation rules", "Created intelligent preprocessing algorithms", "Implemented quality monitoring"],
      "outcomes": ["90% reduction in manual cleaning time", "Improved data quality", "Scalable automation framework"]
    }
  ],
  "skills": [
    {
      "id": "1",
      "name": "Languages & Databases", 
      "skills": [
        {"name": "Python", "level": 95},
        {"name": "SQL (Postgres, MS-SQL, MySQL)", "level": 90},
        {"name": "Java", "level": 80},
        {"name": "C", "level": 75},
        {"name": "React", "level": 85},
        {"name": "Cassandra", "level": 80}
      ]
    }
  ],
  "certifications": [
    {
      "id": "1",
      "title": "AWS Data Engineer Associate",
      "provider": "Amazon Web Services", 
      "date": "Sept 2024"
    }
  ],
  "contact": {
    "email": "ajith.anna5599@gmail.com",
    "linkedin": "https://www.linkedin.com/in/aajith7/",
    "github": "https://github.com/Ajith-oo7", 
    "paragraph": "I am always interested in new opportunities and collaborations. Feel free to reach out if you would like to discuss potential projects or just connect!"
  },
  "journey": {
    "title": "My Journey",
    "description": "From curious data enthusiast to professional data engineer.",
    "paragraph1": "My journey in the data field began with a fascination for extracting insights from raw information. Starting with a solid foundation in computer science, I quickly developed expertise in data engineering and analytics, working across various domains and technologies.",
    "paragraph2": "Along this path, I have continually expanded my skills, adapting to emerging technologies and methodologies, and building a comprehensive toolkit that allows me to tackle complex data challenges with confidence and creativity."
  }
}');